%\input /pros/doc/scidoc/skeleton.tex
\def\version{\it Rev. 1.0 - 5/25/88}
\def\chapter{\it Timing Analysis: Flare Monitor}
%\chapterhead{Science Specifications for the PROS}
%\chapterhead{Timing Analysis: Flare Monitor}
\chapterhead{IX.~Flare Monitor}

\@{Overview}

\noindent
{\it Science Contact}:  Greg Madejski (GSFC)

\noindent
{\it Function Purpose}:  The purpose of this function is to search a
train of data for{\it flares}.  The flares may be either
positive or negative-going; the data may include gaps.  The function
performs a Kolmogorov-Smirnoff test on {\it unbinned} data.  The
essence of this test is to determine the maximum displacement
$D_{max}$ of the observed integral distribution from the steady
distribution.  The test is well described in the ``Numerical Recipes''
by Press {\it et al.} (p.472), and has been used in Feigelson
{\it et al.} (Ap.~J.~302, p.~348).  If the data includes
gaps, it should be de-gapped in the manner described below.
Note that since this is a non-parametric test, it does not measure any
characteristic time scales, but rather reports flare occurrence (or
specifically, a probability that an event as the observed one would
have occurred at random).

\@{Input Data:}

\vskip 16pt

\halign{
\qquad\qquad\qquad#\hfil\quad & #\hfil \cr
$T_S$,$T_E$ & Beginning and end times of the data train \cr
 &~~~~~~~~~~~~~~~~~~~~~~to be investigated \cr
 & \cr
$PH_L$,$PH_H$ & PH bins of the data to be tested \cr
& \cr
$t_1,T_2,t_3,\ldots,t_N$ & Arrival times of a stream of $N$ photons \cr
& ~~~~~~~~~~~~~~~~~~~ recorded between $T_S$ and $T_E$ \cr 
}

\vskip 24pt

\@{Procedure}

This function operates on data that already has been extracted from
images for a source of interest, and thus no positional information is
preserved, since it is not needed.  It is assumed that the photon
events are present in some photon event file, where they are ordered
by event time, and have PH tags attached to them.  It is assumed that there
is no PH histogram available, so the function has to create its own
during the first pass through the data.  If there are gaps in the data,
they have to be removed, and the file made contiguous; that
can be done simultaneously with the first pass -- see description below.  Upon
reading every photon event, the function measures the displacement
$D_i$ of the running sum of counts $i$ from the number of counts that
would be accumulated if the rate $r_e$ were constant ($=r_e \times
t_i$).  The {\it algorithm} for this function is as follows:

{\list

Read input parameters $T_S, T_E, PH_L, PH_H, P_{rand}$

Read sequentially photon events ($t_i, PH_i$) for $T_S
\leq t_i \leq T_E$ to determine $N_E$ ( = total
number of photons within the selected PH)

Determine the live time $T_L (=T_E - T_S - \sum ({\rm~gap~times}))$

Determine the counting rate $r_e$ within the interval of interest
( = $N_E/T_L$)

Read sequentially photon events ($t_i, PH_i$) for
$T_S \leq t_i \leq T_E$; keep track of the number of events read ($ = I$)

For each photon event read, determine $D_i( = \mid r_e \times t_i
- I \mid)$ (an absolute value)

Store the greatest value of $D_i ( = D_{max})$ and corresponding
$t_i$

Calculate the probability of $D_{max} ( = P (D_{max}))$ occurring at
random - see routine {\it KSONE} from Press {\it et al.} (p.474)

}

\@{Output}

$T_{elapsed} ( = T_S - T_E), T_L,
PH_L, PH_H, r_e, D_{max}, P ( D_{max})$ and
$t_i$

Plot the distribution with time on the abscissa [see example
from Press {\it et al.}, Figure 13.5.1]  (optional) 

\@{``De-gapping''}

(Note:  the validity of this
approach still requires a verification by simulations).

The essence of ``de-gapping'' of the data is to reassign time tags to
photons as if there were no gaps between segments of good data:  if
the length of the first gap was $T_{gl}$, then the first photon in the
first segment of data will be assigned time $t_i' = t_i - T_{gl}$
instead of $t_i$, and so on.  In general,
$t_i' = t_i$ - (sum of times of all gaps that occurred
before $t_i$) for all events.


\@{Notes}

One of the disadvantages of the $\chi^2$ test to detect variability
is the fact that it works on {\it binned} data, and furthermore
assumes (usually) a Gaussian distribution of events in each bin.
There may be ways to improve upon it, including a running derivative,
some kind of Erlang process (just a fancy name for probability of an
occurrence of $n$ events in a window, of a fixed length, which is
sliding along the time-axis), {\it etc}.  In almost all cases, either there
will be some form of binning of data, or some assumptions would have
to be made about what kind of event we expect.  Furthermore, the above
approaches are somewhat CPU-hungry.  Two tests are proposed here.

To look for flares we should confine ourselves to a fairly
straightforward test(s) which would not present a significant burden
on the computer.  It also would be preferable if the test(s) were
non-parametric, but simply answered the question ``was there a flare
(or flares) in the data?''  Perhaps the simplest means to test the
data is that specified above.  Here a single-tailed Kolmogorov-Smirnov
test is used to compare the data against a constant photon rate.  Such a
test works on integral distributions and would only require as an
input the mean photon rate $R$, and, if desired, the PH channel numbers
of photons to be considered.  It would --- as photons come in --- keep
track of the total number of {\it detected} photons since the
beginning of an interval, and compare it against the
{\it expected} number (under an assumption of a constant rate) by
keeping track (for a given data train) of the maximum difference
$D_{max}$ between the expected and detected totals.  We should keep
track of the elapsed time (for the calculation of the expected total)
by looking at the time-tags of the detected photons.  The probability
that the observed deviation $D_{max}$ would have occurred at random
should be reported in the output.

An alternative test which would give a little more information,
but which is also quite ``lean'' in terms of CPU time, would be to
create a {\it histogram of photon interarrival times}, and
compare it against what would be expected for a pure distribution
expected from the Poisson process (which is in turn exponential).
Again, such a histogram could be created while reading the photon
events sequentially. A statistical test ({\it e.g.} $\chi^2$) could be
applied to compare the two distributions, and a probability of
obtaining such a value of $\chi^2$ at random should be reported.  By
plotting the difference between the measured and expected
distributions, one could visually notice what are the over- or
under-represented time scales.  Such time scales presumably correspond
to the counting rate at the time of a flares (or dips; note that
a ``flare'' can be both positive or negative going), and
thus are an indication of how bright the source got.

It would be good to incorporate both tests into the Timing Package,
but the K-S test appears to be better for flare searches.  The second
test is likely to be more sensitive than the K-S for periodic and
aperiodic variability (as opposed to single event flares), which in
turn may or may not be good.

\vfill\eject
